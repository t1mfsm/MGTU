import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import io

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelBinarizer
from sklearn.metrics import (
    accuracy_score, confusion_matrix, classification_report, roc_curve, auc
)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

from sklearn.decomposition import PCA

st.set_page_config(page_title="ML Analyzer", layout="wide")
st.title("üå∏ –ê–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (Iris Dataset)")

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
dataset = load_iris()
X = pd.DataFrame(dataset.data, columns=dataset.feature_names)
y = dataset.target
target_names = dataset.target_names

# –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä
st.sidebar.header("üîé –§–∏–ª—å—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
filter_feature = st.sidebar.selectbox("–ü—Ä–∏–∑–Ω–∞–∫ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏", X.columns)
min_val, max_val = float(X[filter_feature].min()), float(X[filter_feature].max())
val_range = st.sidebar.slider("–î–∏–∞–ø–∞–∑–æ–Ω", min_val, max_val, (min_val, max_val), step=0.1)
filtered_idx = X[filter_feature].between(val_range[0], val_range[1])
X = X[filtered_idx]
y = y[filtered_idx]

# –ë–ª–æ–∫: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
with st.expander("‚ÑπÔ∏è –û–ø–∏—Å–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ Iris"):
    st.markdown(f"""
        **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏—Ä–∏—Å–æ–≤ (Iris)** ‚Äî –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç, –≤–∫–ª—é—á–∞—é—â–∏–π 150 –æ–±—Ä–∞–∑—Ü–æ–≤ —Ü–≤–µ—Ç–∫–æ–≤ —Ç—Ä—ë—Ö –≤–∏–¥–æ–≤:
        - **Setosa**, **Versicolor**, **Virginica**

        **–ü—Ä–∏–∑–Ω–∞–∫–∏ (4)**:
        - –î–ª–∏–Ω–∞ –∏ —à–∏—Ä–∏–Ω–∞ —á–∞—à–µ–ª–∏—Å—Ç–∏–∫–∞
        - –î–ª–∏–Ω–∞ –∏ —à–∏—Ä–∏–Ω–∞ –ª–µ–ø–µ—Å—Ç–∫–∞
    """)
    st.dataframe(X.join(pd.Series(y, name="target")))

# –ì—Ä–∞—Ñ–∏–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
st.subheader("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–ª–∞—Å—Å–∞–º")
selected_feature = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫", X.columns)
fig, ax = plt.subplots()
for label in np.unique(y):
    sns.kdeplot(X[selected_feature][y == label], label=target_names[label], fill=True, ax=ax)
plt.legend()
st.pyplot(fig)

# –ì—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
st.subheader("üü† –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (–ö–ª–∞—Å—Å—ã)")
fig, ax = plt.subplots()
sns.countplot(x=y, ax=ax)
ax.set_xticklabels(target_names)
plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π")
st.pyplot(fig)

# –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
st.subheader("üìà –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã")
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

fig, ax = plt.subplots()
for i, label in enumerate(target_names):
    ax.plot(X_scaled[y == i, :].T, color=sns.color_palette("Set2")[i], alpha=0.3)
ax.set_title("–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã")
ax.set_xticks(np.arange(X_scaled.shape[1]))
ax.set_xticklabels(X.columns, rotation=45)
st.pyplot(fig)

# –ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
st.subheader("üìä –ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
corr_matrix = X.corr()
fig, ax = plt.subplots()
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", ax=ax)
plt.title("–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
st.pyplot(fig)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–µ–π
st.sidebar.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–µ–π")
test_size = st.sidebar.slider("–î–æ–ª—è —Ç–µ—Å—Ç–∞", 0.1, 0.5, 0.3)

models_selected = st.sidebar.multiselect(
    "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏:", ["–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è", "–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å", "SVM"],
    default=["–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è", "–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å"]
)

params = {}
if "–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è" in models_selected:
    params["lr_C"] = st.sidebar.slider("C (LogReg)", 0.01, 10.0, 1.0)
if "–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å" in models_selected:
    params["rf_n_estimators"] = st.sidebar.slider("n_estimators (RF)", 10, 200, 100)
if "SVM" in models_selected:
    params["svm_C"] = st.sidebar.slider("C (SVM)", 0.01, 10.0, 1.0)

# –û–±—É—á–µ–Ω–∏–µ
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

results = {}

st.subheader("üèãÔ∏è –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")

for model_name in models_selected:
    if model_name == "–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è":
        model = LogisticRegression(C=params["lr_C"], max_iter=200)
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
    elif model_name == "–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å":
        model = RandomForestClassifier(n_estimators=params["rf_n_estimators"])
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
    elif model_name == "SVM":
        model = SVC(C=params["svm_C"], probability=True)
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)

    acc = accuracy_score(y_test, y_pred)
    results[model_name] = {
        "model": model,
        "accuracy": acc,
        "y_pred": y_pred,
        "report": classification_report(y_test, y_pred, target_names=target_names, output_dict=True)
    }

# –¢–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫
st.markdown("### üìã –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–µ–π")
summary = pd.DataFrame({
    model: {
        "Accuracy": f"{res['accuracy']:.2f}",
        "Precision": f"{np.mean([res['report'][cls]['precision'] for cls in target_names]):.2f}",
        "Recall": f"{np.mean([res['report'][cls]['recall'] for cls in target_names]):.2f}",
    }
    for model, res in results.items()
}).T
st.dataframe(summary)

# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –æ—Ç—á—ë—Ç—ã
st.markdown("### üßæ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –æ—Ç—á—ë—Ç—ã")
for model_name, res in results.items():
    st.markdown(f"**{model_name}**")
    report_df = pd.DataFrame(res["report"]).T
    st.dataframe(report_df)

# –ú–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫
st.markdown("### üîç –ú–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫")
for model_name, res in results.items():
    st.markdown(f"#### {model_name}")
    cm = confusion_matrix(y_test, res["y_pred"])
    fig, ax = plt.subplots()
    sns.heatmap(cm, annot=True, fmt='d', cmap="Blues", xticklabels=target_names, yticklabels=target_names)
    plt.xlabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ")
    plt.ylabel("–ò—Å—Ç–∏–Ω–∞")
    st.pyplot(fig)

# –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
if "–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å" in results:
    st.markdown("### üåü –°–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Random Forest)")
    rf_model = results["–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å"]["model"]
    importances = rf_model.feature_importances_
    imp_df = pd.DataFrame({
        "–ü—Ä–∏–∑–Ω–∞–∫": X.columns,
        "–í–∞–∂–Ω–æ—Å—Ç—å": importances
    }).sort_values("–í–∞–∂–Ω–æ—Å—Ç—å", ascending=False)
    st.dataframe(imp_df)

    fig, ax = plt.subplots()
    sns.barplot(data=imp_df, x="–í–∞–∂–Ω–æ—Å—Ç—å", y="–ü—Ä–∏–∑–Ω–∞–∫", palette="viridis")
    st.pyplot(fig)

# PCA –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
st.markdown("### üß¨ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (PCA)")
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)
df_vis = pd.DataFrame(X_pca, columns=["PC1", "PC2"])
df_vis["–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å"] = [target_names[i] for i in y]

fig, ax = plt.subplots()
sns.scatterplot(data=df_vis, x="PC1", y="PC2", hue="–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å", palette="Set2", s=80)
plt.title("PCA ‚Äî –ò—Å—Ç–∏–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã")
st.pyplot(fig)

if len(results) == 1:
    model_name = list(results.keys())[0]
    model = results[model_name]["model"]
    if model_name == "–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å":
        y_pred_vis = model.predict(X)
    else:
        X_scaled_full = scaler.transform(X)
        y_pred_vis = model.predict(X_scaled_full)

    df_vis["–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"] = [target_names[i] for i in y_pred_vis]
    fig2, ax2 = plt.subplots()
    sns.scatterplot(data=df_vis, x="PC1", y="PC2", hue="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ", palette="Set1", s=80)
    plt.title(f"PCA ‚Äî –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏: {model_name}")
    st.pyplot(fig2)

# ROC-–∫—Ä–∏–≤—ã–µ
if len(np.unique(y)) == 2:
    st.markdown("### üìâ ROC-–∫—Ä–∏–≤—ã–µ")
    lb = LabelBinarizer()
    y_test_bin = lb.fit_transform(y_test).ravel()
    for model_name, res in results.items():
        model = res["model"]
        if hasattr(model, "predict_proba"):
            probs = model.predict_proba(X_test_scaled if model_name != "–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å" else X_test)[:, 1]
            fpr, tpr, _ = roc_curve(y_test_bin, probs)
            roc_auc = auc(fpr, tpr)

            fig, ax = plt.subplots()
            ax.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}")
            ax.plot([0, 1], [0, 1], "--", color="gray")
            ax.set_title(f"ROC-–∫—Ä–∏–≤–∞—è ‚Äî {model_name}")
            ax.set_xlabel("FPR")
            ax.set_ylabel("TPR")
            ax.legend()
            st.pyplot(fig)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
st.markdown("### üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å")
model_to_save = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è", list(results.keys()))
model_file = io.BytesIO()
joblib.dump(results[model_to_save]["model"], model_file)
st.download_button("üì• –°–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å", data=model_file.getvalue(), file_name=f"{model_to_save}.joblib")
